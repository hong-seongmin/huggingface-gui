#!/usr/bin/env python3
"""
ëª¨ë¸ ë¡œë”© ë¬¸ì œ ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸
"""
import threading
import time
import psutil
import torch
import os
from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig

def check_system_resources():
    """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸"""
    print("=== ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸ ===")
    
    # ë©”ëª¨ë¦¬
    memory = psutil.virtual_memory()
    print(f"ì´ ë©”ëª¨ë¦¬: {memory.total / (1024**3):.1f}GB")
    print(f"ì‚¬ìš© ì¤‘: {memory.used / (1024**3):.1f}GB ({memory.percent:.1f}%)")
    print(f"ì‚¬ìš© ê°€ëŠ¥: {memory.available / (1024**3):.1f}GB")
    
    # GPU
    if torch.cuda.is_available():
        print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: Yes")
        for i in range(torch.cuda.device_count()):
            total = torch.cuda.get_device_properties(i).total_memory
            allocated = torch.cuda.memory_allocated(i)
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
            print(f"  ì´: {total / (1024**3):.1f}GB, í• ë‹¹: {allocated / (1024**3):.1f}GB")
    else:
        print("CUDA ì‚¬ìš© ë¶ˆê°€ëŠ¥")
    
    print()

def test_simple_loading():
    """ê°„ë‹¨í•œ ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("=== ê°„ë‹¨í•œ ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸ ===")
    model_id = "tabularisai/multilingual-sentiment-analysis"
    
    try:
        print("1. Config ë¡œë”©...")
        config = AutoConfig.from_pretrained(model_id)
        print(f"   ì™„ë£Œ: {config.architectures}")
        
        print("2. í† í¬ë‚˜ì´ì € ë¡œë”©...")
        start_time = time.time()
        tokenizer = AutoTokenizer.from_pretrained(model_id)
        print(f"   ì™„ë£Œ ({time.time() - start_time:.1f}ì´ˆ)")
        
        print("3. ëª¨ë¸ ë¡œë”©...")
        start_time = time.time()
        model = AutoModelForSequenceClassification.from_pretrained(
            model_id,
            trust_remote_code=True
        )
        print(f"   ì™„ë£Œ ({time.time() - start_time:.1f}ì´ˆ)")
        
        print("4. ê°„ë‹¨í•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸...")
        inputs = tokenizer("This is a test", return_tensors="pt")
        with torch.no_grad():
            outputs = model(**inputs)
        print(f"   ì™„ë£Œ, ì¶œë ¥ í¬ê¸°: {outputs.logits.shape}")
        
        print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        return True
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_threaded_loading():
    """ìŠ¤ë ˆë“œì—ì„œ ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("=== ìŠ¤ë ˆë“œ ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸ ===")
    
    result = {"success": False, "error": None, "model": None, "tokenizer": None}
    
    def load_in_thread():
        try:
            print("[ìŠ¤ë ˆë“œ] ëª¨ë¸ ë¡œë”© ì‹œì‘...")
            model_id = "tabularisai/multilingual-sentiment-analysis"
            
            print("[ìŠ¤ë ˆë“œ] í† í¬ë‚˜ì´ì € ë¡œë”©...")
            tokenizer = AutoTokenizer.from_pretrained(model_id)
            
            print("[ìŠ¤ë ˆë“œ] ëª¨ë¸ ë¡œë”©...")
            model = AutoModelForSequenceClassification.from_pretrained(
                model_id,
                trust_remote_code=True
            )
            
            result["model"] = model
            result["tokenizer"] = tokenizer
            result["success"] = True
            print("[ìŠ¤ë ˆë“œ] ë¡œë”© ì™„ë£Œ!")
            
        except Exception as e:
            result["error"] = str(e)
            print(f"[ìŠ¤ë ˆë“œ] ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
    
    # ìŠ¤ë ˆë“œ ì‹œì‘
    thread = threading.Thread(target=load_in_thread)
    thread.daemon = True
    thread.start()
    
    # íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ëŒ€ê¸°
    timeout = 60  # 60ì´ˆ
    start_time = time.time()
    
    while thread.is_alive() and (time.time() - start_time) < timeout:
        print(f"ëŒ€ê¸° ì¤‘... ({time.time() - start_time:.1f}ì´ˆ)")
        time.sleep(2)
    
    if thread.is_alive():
        print("âŒ íƒ€ì„ì•„ì›ƒ! ìŠ¤ë ˆë“œê°€ ì™„ë£Œë˜ì§€ ì•ŠìŒ")
        return False
    
    if result["success"]:
        print("âœ… ìŠ¤ë ˆë“œ ë¡œë”© ì„±ê³µ!")
        return True
    else:
        print(f"âŒ ìŠ¤ë ˆë“œ ë¡œë”© ì‹¤íŒ¨: {result['error']}")
        return False

def test_memory_pressure():
    """ë©”ëª¨ë¦¬ ì••ë°• ìƒí™©ì—ì„œ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("=== ë©”ëª¨ë¦¬ ì••ë°• ìƒí™© í…ŒìŠ¤íŠ¸ ===")
    
    # í˜„ì¬ ë©”ëª¨ë¦¬ ìƒíƒœ
    initial_memory = psutil.virtual_memory()
    print(f"ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {initial_memory.percent:.1f}%")
    
    if initial_memory.percent > 80:
        print("âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ì´ë¯¸ ë†’ìŒ (80% ì´ìƒ)")
        return False
    
    # ë©”ëª¨ë¦¬ ì••ë°• ìƒì„± (1GB í• ë‹¹)
    memory_hog = []
    try:
        print("ë©”ëª¨ë¦¬ ì••ë°• ìƒì„± ì¤‘...")
        for i in range(10):  # 100MBì”© 10ë²ˆ
            data = bytearray(100 * 1024 * 1024)  # 100MB
            memory_hog.append(data)
            current_memory = psutil.virtual_memory()
            print(f"  í• ë‹¹ {(i+1)*100}MB, ì‚¬ìš©ë¥ : {current_memory.percent:.1f}%")
            
            if current_memory.percent > 85:
                print("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  85% ë„ë‹¬, ì¤‘ë‹¨")
                break
        
        # ì••ë°• ìƒí™©ì—ì„œ ëª¨ë¸ ë¡œë”© ì‹œë„
        print("ì••ë°• ìƒí™©ì—ì„œ ëª¨ë¸ ë¡œë”© ì‹œë„...")
        return test_simple_loading()
        
    finally:
        # ë©”ëª¨ë¦¬ í•´ì œ
        print("ë©”ëª¨ë¦¬ í•´ì œ ì¤‘...")
        del memory_hog
        import gc
        gc.collect()

def main():
    print("ëª¨ë¸ ë¡œë”© ë¬¸ì œ ì§„ë‹¨ ì‹œì‘\n")
    
    # 1. ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸
    check_system_resources()
    
    # 2. ê°„ë‹¨í•œ ë¡œë”© í…ŒìŠ¤íŠ¸
    simple_result = test_simple_loading()
    print()
    
    # 3. ìŠ¤ë ˆë“œ ë¡œë”© í…ŒìŠ¤íŠ¸
    thread_result = test_threaded_loading()
    print()
    
    # 4. ë©”ëª¨ë¦¬ ì••ë°• í…ŒìŠ¤íŠ¸
    memory_result = test_memory_pressure()
    print()
    
    # ê²°ê³¼ ìš”ì•½
    print("=== ì§„ë‹¨ ê²°ê³¼ ìš”ì•½ ===")
    print(f"ê°„ë‹¨í•œ ë¡œë”©: {'âœ… ì„±ê³µ' if simple_result else 'âŒ ì‹¤íŒ¨'}")
    print(f"ìŠ¤ë ˆë“œ ë¡œë”©: {'âœ… ì„±ê³µ' if thread_result else 'âŒ ì‹¤íŒ¨'}")
    print(f"ë©”ëª¨ë¦¬ ì••ë°• í…ŒìŠ¤íŠ¸: {'âœ… ì„±ê³µ' if memory_result else 'âŒ ì‹¤íŒ¨'}")
    
    if simple_result and not thread_result:
        print("\nğŸ” ì¶”ì • ì›ì¸: ìŠ¤ë ˆë“œ í™˜ê²½ì—ì„œì˜ ë¬¸ì œ")
        print("   - GIL (Global Interpreter Lock) ë¬¸ì œ")
        print("   - ìŠ¤ë ˆë“œ ê°„ ë¦¬ì†ŒìŠ¤ ì¶©ëŒ")
        print("   - ë©”ëª¨ë¦¬ ê³µìœ  ë¬¸ì œ")
    
    elif not simple_result:
        print("\nğŸ” ì¶”ì • ì›ì¸: ê¸°ë³¸ì ì¸ ëª¨ë¸ ë¡œë”© ë¬¸ì œ")
        print("   - ë©”ëª¨ë¦¬ ë¶€ì¡±")
        print("   - ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ")
        print("   - ì˜ì¡´ì„± ë¬¸ì œ")

if __name__ == "__main__":
    main()