"""
Model management UI components for Streamlit.
"""
import streamlit as st
from typing import Dict, Any, Optional, List
from core.state_manager import state_manager
from core.cache_manager import cache_manager
from core.logging_config import get_logger
from utils.validators import validate_model_id
from utils.formatters import format_json, format_model_info

logger = get_logger(__name__)


def render_model_status_banner():
    """Render model status banner."""
    status_items = []

    if st.session_state.get('model_path_input', ''):
        status_items.append(f"ìž…ë ¥ ê²½ë¡œ: {st.session_state['model_path_input']}")

    if st.session_state.get('current_model_analysis'):
        status_items.append("ë¶„ì„ ê²°ê³¼ ì¡´ìž¬")

    if st.session_state.get('selected_cached_model', 'ì§ì ‘ ìž…ë ¥') != 'ì§ì ‘ ìž…ë ¥':
        status_items.append(f"ìºì‹œ ì„ íƒ: {st.session_state['selected_cached_model']}")

    if status_items:
        st.success(f"ðŸŸ¢ **ì €ìž¥ëœ ìƒíƒœ**: {', '.join(status_items)}")
    else:
        st.info("ðŸ”µ **ëª¨ë¸ ê´€ë¦¬**: ìƒˆë¡œìš´ ì„¸ì…˜ - ì•„ëž˜ì—ì„œ ëª¨ë¸ì„ ì„ íƒí•˜ê±°ë‚˜ ìž…ë ¥í•˜ì„¸ìš”")


def render_cached_model_selector():
    """Render cached model selector."""
    if not st.session_state.get('cache_info'):
        st.info("ìºì‹œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìºì‹œë¥¼ ìŠ¤ìº”í•´ì£¼ì„¸ìš”.")
        return

    with st.expander("ðŸ—‚ï¸ ìºì‹œëœ ëª¨ë¸ì—ì„œ ì„ íƒ", expanded=False):
        cached_models = []
        for repo in st.session_state['cache_info'].repos:
            cached_models.append(repo.repo_id)

        if cached_models:
            # ì €ìž¥ëœ ì„ íƒê°’ ë³µì›
            saved_selection = st.session_state.get('selected_cached_model', 'ì§ì ‘ ìž…ë ¥')
            try:
                default_index = (["ì§ì ‘ ìž…ë ¥"] + cached_models).index(saved_selection)
            except ValueError:
                default_index = 0

            selected_cached_model = st.selectbox(
                "ìºì‹œëœ ëª¨ë¸ ì„ íƒ",
                options=["ì§ì ‘ ìž…ë ¥"] + cached_models,
                index=default_index,
                key="cached_model_select"
            )

            if selected_cached_model != "ì§ì ‘ ìž…ë ¥":
                # ìºì‹œëœ ëª¨ë¸ ì„ íƒ ì‹œ ìžë™ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
                st.session_state['model_path_input'] = selected_cached_model
                st.session_state['selected_cached_model'] = selected_cached_model
                state_manager.save_state(st.session_state)
                st.success(f"âœ… ì„ íƒëœ ëª¨ë¸: `{selected_cached_model}`")
            else:
                st.session_state['selected_cached_model'] = 'ì§ì ‘ ìž…ë ¥'
                state_manager.save_state(st.session_state)
        else:
            st.info("ìºì‹œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")


def render_model_input():
    """Render model path input section."""
    st.markdown("#### ðŸ”— ëª¨ë¸ ê²½ë¡œ ìž…ë ¥")

    model_path = st.text_input(
        "ëª¨ë¸ ê²½ë¡œ",
        key="model_path_input",
        placeholder="ì˜ˆ: tabularisai/multilingual-sentiment-analysis",
        help="ë¡œì»¬ ê²½ë¡œ ë˜ëŠ” HuggingFace ëª¨ë¸ IDë¥¼ ìž…ë ¥í•˜ì„¸ìš”"
    )

    # Validate input
    if model_path:
        is_valid, error_msg = validate_model_id(model_path)
        if not is_valid:
            st.warning(f"âš ï¸ {error_msg}")

    return model_path


def render_model_actions(model_path: str):
    """Render model action buttons."""
    st.markdown("#### âš¡ ì•¡ì…˜")
    col1, col2, col3, col4 = st.columns([1, 1, 1, 1])

    with col1:
        analyze_clicked = st.button("ðŸ” ëª¨ë¸ ë¶„ì„", use_container_width=True, type="secondary")

    with col2:
        load_clicked = st.button("ðŸ“¤ ëª¨ë¸ ë¡œë“œ", use_container_width=True, type="primary")

    with col3:
        refresh_clicked = st.button("ðŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨", use_container_width=True)

    with col4:
        clear_clicked = st.button("ðŸ§¹ ìž…ë ¥ ì§€ìš°ê¸°", use_container_width=True)

    # Handle button actions
    if analyze_clicked:
        handle_analyze_model(model_path)

    if load_clicked:
        handle_load_model(model_path)

    if refresh_clicked:
        st.rerun()

    if clear_clicked:
        handle_clear_input()


def handle_analyze_model(model_path: str):
    """Handle model analysis action."""
    if not model_path:
        st.error("âŒ ëª¨ë¸ ê²½ë¡œë¥¼ ìž…ë ¥í•˜ì„¸ìš”.")
        return

    try:
        with st.spinner("ðŸ” ëª¨ë¸ ë¶„ì„ ì¤‘..."):
            if 'model_manager' not in st.session_state:
                st.error("âŒ ëª¨ë¸ ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return

            analysis = st.session_state['model_manager'].analyze_model(model_path)

            if 'error' in analysis:
                st.error(f"âŒ ëª¨ë¸ ë¶„ì„ ì‹¤íŒ¨: {analysis['error']}")
            else:
                st.session_state['current_model_analysis'] = analysis
                state_manager.save_state(st.session_state)
                st.success("âœ… ëª¨ë¸ ë¶„ì„ ì™„ë£Œ!")

                # Show analysis results
                render_analysis_results(analysis)

    except Exception as e:
        error_msg = f"ëª¨ë¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        st.error(error_msg)
        logger.error(error_msg)


def handle_load_model(model_path: str):
    """Handle model loading action."""
    if not model_path:
        st.error("âŒ ëª¨ë¸ ê²½ë¡œë¥¼ ìž…ë ¥í•˜ì„¸ìš”.")
        return

    try:
        if 'model_manager' not in st.session_state:
            st.error("âŒ ëª¨ë¸ ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        # Generate model name
        if st.session_state['model_manager']._is_huggingface_model_id(model_path):
            model_name = model_path.split('/')[-1]
        else:
            model_name = model_path.replace('/', '_').replace('\\', '_')

        with st.spinner(f"ðŸ“¤ ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}"):
            success = st.session_state['model_manager'].load_model(model_path, model_name)

            if success:
                st.success(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_name}")
                state_manager.save_state(st.session_state)
            else:
                st.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {model_name}")

    except Exception as e:
        error_msg = f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        st.error(error_msg)
        logger.error(error_msg)


def handle_clear_input():
    """Handle clear input action."""
    st.session_state['model_path_input'] = ''
    st.session_state['selected_cached_model'] = 'ì§ì ‘ ìž…ë ¥'
    st.session_state['current_model_analysis'] = None
    state_manager.save_state(st.session_state)
    st.success("ðŸ§¹ ìž…ë ¥ì´ ì§€ì›Œì¡ŒìŠµë‹ˆë‹¤.")
    st.rerun()


def render_analysis_results(analysis: Dict[str, Any]):
    """Render model analysis results."""
    if not analysis or 'error' in analysis:
        return

    st.subheader("ðŸ“Š ëª¨ë¸ ë¶„ì„ ê²°ê³¼")

    # Basic model info
    if 'model_info' in analysis:
        with st.expander("ðŸ“‹ ëª¨ë¸ ê¸°ë³¸ ì •ë³´", expanded=True):
            model_info = analysis['model_info']
            st.markdown(format_model_info(model_info))

    # Architecture details
    if 'architecture' in analysis:
        with st.expander("ðŸ—ï¸ ì•„í‚¤í…ì²˜ ì •ë³´"):
            st.json(analysis['architecture'])

    # Config information
    if 'config' in analysis:
        with st.expander("âš™ï¸ ëª¨ë¸ ì„¤ì •"):
            st.json(analysis['config'])

    # Task information
    if 'supported_tasks' in analysis:
        with st.expander("ðŸŽ¯ ì§€ì› íƒœìŠ¤í¬"):
            tasks = analysis['supported_tasks']
            if isinstance(tasks, list):
                for task in tasks:
                    st.write(f"â€¢ {task}")
            else:
                st.write(tasks)

    # Performance metrics
    if 'performance' in analysis:
        with st.expander("ðŸ“ˆ ì„±ëŠ¥ ì •ë³´"):
            perf = analysis['performance']
            col1, col2, col3 = st.columns(3)

            with col1:
                if 'memory_usage' in perf:
                    st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", f"{perf['memory_usage']:.1f} MB")

            with col2:
                if 'loading_time' in perf:
                    st.metric("ë¡œë”© ì‹œê°„", f"{perf['loading_time']:.2f}ì´ˆ")

            with col3:
                if 'model_size' in perf:
                    st.metric("ëª¨ë¸ í¬ê¸°", f"{perf['model_size']:.1f} MB")


def render_loaded_models_status():
    """Render loaded models status."""
    if 'model_manager' not in st.session_state:
        return

    manager = st.session_state['model_manager']

    # Loaded models
    if manager.loaded_models:
        st.subheader("âœ… ë¡œë“œëœ ëª¨ë¸")
        for model_name, model_info in manager.loaded_models.items():
            with st.expander(f"ðŸ“¦ {model_name}", expanded=False):
                col1, col2 = st.columns([3, 1])

                with col1:
                    st.write(f"**ê²½ë¡œ**: {model_info.path}")
                    st.write(f"**ë¡œë“œ ì‹œê°„**: {model_info.load_time:.2f}ì´ˆ")
                    if hasattr(model_info, 'memory_usage'):
                        st.write(f"**ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: {model_info.memory_usage:.1f} MB")

                with col2:
                    if st.button(f"ðŸ—‘ï¸ ì–¸ë¡œë“œ", key=f"unload_{model_name}"):
                        if manager.unload_model(model_name):
                            st.success(f"ëª¨ë¸ {model_name}ì´ ì–¸ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.rerun()
                        else:
                            st.error(f"ëª¨ë¸ {model_name} ì–¸ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    # Loading models
    if manager.loading_models:
        st.subheader("â³ ë¡œë”© ì¤‘ì¸ ëª¨ë¸")
        for model_name in manager.loading_models:
            st.info(f"ðŸ”„ {model_name} ë¡œë”© ì¤‘...")

    # Failed models
    if manager.failed_models:
        st.subheader("âŒ ë¡œë“œ ì‹¤íŒ¨í•œ ëª¨ë¸")
        for model_name, error in manager.failed_models.items():
            st.error(f"ðŸ’¥ {model_name}: {error}")


def render_model_load_section():
    """Render model loading section."""
    with st.container():
        st.subheader("ðŸ“¥ ìƒˆ ëª¨ë¸ ë¡œë“œ")

        # Cached model selector
        render_cached_model_selector()

        # Model input
        model_path = render_model_input()

        # Action buttons
        render_model_actions(model_path)

        # Show current analysis if exists
        if st.session_state.get('current_model_analysis'):
            render_analysis_results(st.session_state['current_model_analysis'])


def render_model_management():
    """Render complete model management UI."""
    try:
        st.header("ðŸ¤– ëª¨ë¸ ê´€ë¦¬")

        # Initialize state
        init_model_management_state()

        # Status banner
        render_model_status_banner()

        st.markdown("---")

        # Model loading section
        render_model_load_section()

        st.markdown("---")

        # Loaded models status
        render_loaded_models_status()

        # Model management tips
        with st.expander("ðŸ’¡ ëª¨ë¸ ê´€ë¦¬ íŒ"):
            st.markdown("""
            - **ëª¨ë¸ ë¶„ì„**: ë¡œë“œí•˜ê¸° ì „ì— ëª¨ë¸ì„ ë¶„ì„í•˜ì—¬ í˜¸í™˜ì„±ì„ í™•ì¸í•˜ì„¸ìš”
            - **ë©”ëª¨ë¦¬ ê´€ë¦¬**: í° ëª¨ë¸ë“¤ì€ ë§Žì€ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. í•„ìš”í•˜ì§€ ì•Šì€ ëª¨ë¸ì€ ì–¸ë¡œë“œí•˜ì„¸ìš”
            - **ìºì‹œ í™œìš©**: í•œë²ˆ ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ì€ ìºì‹œì—ì„œ ë¹ ë¥´ê²Œ ë¡œë“œë©ë‹ˆë‹¤
            """)
    except Exception as e:
        logger.error(f"Model management UI error: {e}")
        st.error(f"ëª¨ë¸ ê´€ë¦¬ íŽ˜ì´ì§€ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.info("íŽ˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ê´€ë¦¬ìžì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")


def init_model_management_state():
    """Initialize model management-related session state."""
    if 'model_path_input' not in st.session_state:
        st.session_state['model_path_input'] = ''

    if 'selected_cached_model' not in st.session_state:
        st.session_state['selected_cached_model'] = 'ì§ì ‘ ìž…ë ¥'

    if 'current_model_analysis' not in st.session_state:
        st.session_state['current_model_analysis'] = None


def get_model_suggestions(query: str) -> List[str]:
    """
    Get model suggestions based on query.

    Args:
        query: Search query

    Returns:
        List of suggested model IDs
    """
    # This would typically query HuggingFace Hub or a local index
    # For now, return some popular models
    popular_models = [
        "microsoft/DialoGPT-medium",
        "tabularisai/multilingual-sentiment-analysis",
        "bert-base-uncased",
        "gpt2",
        "distilbert-base-uncased",
        "facebook/blenderbot-400M-distill",
        "microsoft/DialoGPT-small",
        "cardiffnlp/twitter-roberta-base-sentiment-latest",
    ]

    if not query:
        return popular_models[:5]

    # Simple filtering
    filtered = [model for model in popular_models if query.lower() in model.lower()]
    return filtered[:5]