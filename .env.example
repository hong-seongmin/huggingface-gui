# Environment Variables for HuggingFace GUI

# =================
# SERVER CONFIGURATION  
# =================
HOST=127.0.0.1
PORT=8501
FASTAPI_HOST=127.0.0.1
FASTAPI_PORT=8000

# =================
# MODEL CONFIGURATION
# =================
# Model cache directory (default: /tmp/hf_model_cache)
HF_MODEL_CACHE_DIR=/tmp/hf_model_cache

# Default device for model loading (auto, cpu, cuda, mps)
DEFAULT_DEVICE=auto

# Maximum number of models to load simultaneously
MAX_CONCURRENT_MODELS=2

# =================
# HUGGINGFACE HUB SETTINGS
# =================
# HuggingFace Hub token for private models (optional)
# HF_TOKEN=your_token_here

# Offline mode (true/false)
HF_HUB_OFFLINE=false
TRANSFORMERS_OFFLINE=false

# Disable telemetry (true/false)
HF_HUB_DISABLE_TELEMETRY=false

# Tokenizers parallelism (true/false)
TOKENIZERS_PARALLELISM=false

# =================
# LOGGING CONFIGURATION
# =================
# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Log file path
LOG_FILE=app_debug.log

# =================
# STREAMLIT CONFIGURATION
# =================
# Streamlit server settings
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0
STREAMLIT_SERVER_HEADLESS=true
STREAMLIT_BROWSER_GATHER_USAGE_STATS=false

# =================
# PERFORMANCE SETTINGS
# =================
# Memory limit for models (in GB)
MAX_MODEL_MEMORY=8

# GPU memory fraction to use (0.0-1.0)
GPU_MEMORY_FRACTION=0.8

# Enable model quantization (true/false)
ENABLE_QUANTIZATION=false

# =================
# SECURITY SETTINGS
# =================
# Enable CORS (true/false)
ENABLE_CORS=true

# Allowed origins for CORS (comma-separated)
CORS_ORIGINS=*

# Enable API authentication (true/false)
ENABLE_AUTH=false

# API key for authentication (if ENABLE_AUTH=true)
# API_KEY=your_api_key_here